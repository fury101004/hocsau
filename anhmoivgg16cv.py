import os
import cv2
import numpy as np
import tensorflow as tf
import mediapipe as mp
from tkinter import Tk, filedialog

# ·∫®n b·ªõt log TensorFlow
os.environ["TF_ENABLE_ONEDNN_OPTS"] = "0"
os.environ["TF_CPP_MIN_LOG_LEVEL"] = "3"

# ==== Load model ====
model = tf.keras.models.load_model("vgg16_cpu_model2.h5")

# ==== Nh√£n (gi·ªëng train_gen.class_indices) ====
label_map = {
    0: "angry", 1: "disgust", 2: "fear",
    3: "happy", 4: "sad", 5: "surprise", 6: "neutral"
}

# K√≠ch th∆∞·ªõc ·∫£nh input ƒë√∫ng v·ªõi model ƒë√£ train
img_size = (128, 128)

# ==== H√†m ƒë·ªçc ·∫£nh Unicode-safe ====
def read_image_unicode(path):
    with open(path, "rb") as f:
        data = np.asarray(bytearray(f.read()), dtype=np.uint8)
        return cv2.imdecode(data, cv2.IMREAD_COLOR)

# ==== Mediapipe Face Detection ====
mp_face = mp.solutions.face_detection


def predict_image(image_path):
    img = read_image_unicode(image_path)
    if img is None:
        print("‚ùå Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c ·∫£nh:", image_path)
        return

    # Chuy·ªÉn sang RGB cho Mediapipe
    rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    with mp_face.FaceDetection(model_selection=1, min_detection_confidence=0.5) as face_detection:
        results = face_detection.process(rgb_img)

        if not results.detections:
            print("‚ùå Kh√¥ng t√¨m th·∫•y khu√¥n m·∫∑t trong ·∫£nh:", image_path)
        else:
            h, w, _ = img.shape
            for detection in results.detections:
                bboxC = detection.location_data.relative_bounding_box
                # Gi·ªõi h·∫°n t·ªça ƒë·ªô ƒë·ªÉ tr√°nh v√πng c·∫Øt ra ngo√†i ·∫£nh
                x = max(int(bboxC.xmin * w), 0)
                y = max(int(bboxC.ymin * h), 0)
                bw = int(bboxC.width * w)
                bh = int(bboxC.height * h)

                # Gi·ªõi h·∫°n chi·ªÅu r·ªông, chi·ªÅu cao v√πng c·∫Øt kh√¥ng v∆∞·ª£t qu√° ·∫£nh
                bw = min(bw, w - x)
                bh = min(bh, h - y)

                if bw <= 0 or bh <= 0:
                    print("‚ö†Ô∏è V√πng khu√¥n m·∫∑t kh√¥ng h·ª£p l·ªá, b·ªè qua.")
                    continue

                # C·∫Øt khu√¥n m·∫∑t
                face = img[y:y+bh, x:x+bw]
                if face.size == 0:
                    print("‚ö†Ô∏è Kh√¥ng c·∫Øt ƒë∆∞·ª£c m·∫∑t, b·ªè qua.")
                    continue

                # Resize v·ªÅ 128x128 (chu·∫©n v·ªõi model)
                face_resized = cv2.resize(face, img_size)
                face_resized = face_resized.astype("float32") / 255.0
                face_resized = np.expand_dims(face_resized, axis=0)  # (1,128,128,3)

                # D·ª± ƒëo√°n
                pred = model.predict(face_resized, verbose=0)
                label = label_map[np.argmax(pred)]
                confidence = np.max(pred) * 100

                print(f"üëâ ·∫¢nh: {image_path} ‚Üí {label} ({confidence:.2f}%)")

                # V·∫Ω khung + nh√£n
                cv2.rectangle(img, (x, y), (x + bw, y + bh), (0, 255, 0), 2)
                cv2.putText(img, f"{label} {confidence:.1f}%", (x, y - 10),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)

    # Hi·ªÉn th·ªã k·∫øt qu·∫£
    cv2.imshow("K·∫øt qu·∫£ d·ª± ƒëo√°n - VGG16 + Mediapipe", img)
    cv2.waitKey(0)
    cv2.destroyAllWindows()


if __name__ == "__main__":
    # M·ªü h·ªôp tho·∫°i ch·ªçn ·∫£nh
    root = Tk()
    root.withdraw()
    file_path = filedialog.askopenfilename(
        title="Ch·ªçn ·∫£nh ƒë·ªÉ d·ª± ƒëo√°n",
        filetypes=[("Image files", "*.jpg *.jpeg *.png *.jfif")]
    )
    if file_path:
        predict_image(file_path)
    else:
        print("‚ùå B·∫°n ch∆∞a ch·ªçn ·∫£nh n√†o.")
